\documentclass[12pt]{../notes}

% Command for Questions
%\question{}

% Command for Notes
% \note{}

% Code to create a minipage where you can type in class notes. 
%%\begin{minipage}[l][2cm][c]{\textwidth}
%\begin{comment}

%\end{comment}
%%\end{minipage}

\usepackage{xurl}

% Begin Document
%==============================================================================
\begin{document}
% Include the Title of the Handout
\ntitle{The Mythos of Model Interpretability}
\textbf{Questions from Canvas Quiz}
\begin{itemize}
\item According to Section 3, in what ways could linear models be considered ``interpretable''?
\item According to Section 4, why are linear models not necessarily more interpretable than complex neural networks? 
\item Please articulate at least one thing you learned as a result of studying this article. 
\end{itemize}

\nspace

\textbf{Additional Discussion Questions} 

% Include Numbered Sections
\question{In what ways is a linear model ``interpretable''? In what ways is it NOT interpretable?}

\begin{minipage}[l][8cm][c]{\textwidth}
\note{Interpretable:
\bi
\item Relatively easy to explain how the model works. 
\item Each explanatory variable is associated with a single number that we can directly interpret (assuming no interactions). 
\ei}

\note{NOT Interpretable:
\bi
\item Linear models are often heavily manipulated ``by hand'', making it hard to separate what is a product of the data, from what is a product of our manipulations. 
\item If our associations are plagued by \textbf{confounding variables} or the data itself contains bias or prejudice, we may make inappropriate conclusions from our model, regardless of the satisfaction of assumptions.  
\ei}
\end{minipage}

\question{Why should we care about interpretability?}

\begin{minipage}[l][4cm][c]{\textwidth}
\note{Consider the European Unions Law requiring a "right to explanation'' (\url{https://arxiv.org/pdf/1606.08813.pdf}). As more and more significant decisions begin being made by algorithms, more and more people will want to know why and how those decisions are being made. 
\newline
\newline
Example: a person would probably like to know why a statistical algorithm denied them the opportunity for a home loan.}
\end{minipage}

\question{How might a statistical model be racist/prejudiced? Are linear models also prone to prejudice? If so, how?}

\begin{minipage}[l][4cm][c]{\textwidth}
\note{If we use historical data to train our models (say loan default risk), and those historical decisions were made in a prejudiced way, the model will likewise learn to be prejudiced. Also, confounding variables (an unaccounted for variable that is highly correlated with two other variables and makes the two other variables look correlated with each other) make can make things like ``race'' or ``gender'' drive model predictions, even if those variables are actually included in the model.}
\end{minipage}

\question{How might statistics be used to ensure that the predictive models of tomorrow don't suffer from the prejudices of yesterday?}

\begin{minipage}[l][4cm][c]{\textwidth}
\note{There is no right answer here. However, a better understanding of how our predictive models work will help us know how and when the results might betray us.}
\end{minipage}

\nspace
\textbf{Interesting Articles}
\begin{itemize}
\item \url{https://www.npr.org/sections/live-updates-protests-for-racial-justice/2020/06/24/883107627/boston-lawmakers-vote-to-ban-use-of-facial-recognition-technology-by-the-city}
\item \url{https://www.npr.org/2020/06/24/882678392/man-says-he-was-falsely-arrested-after-facial-recognition-mistake}
\item \url{https://www.theverge.com/2018/3/21/17144260/healthcare-medicaid-algorithm-arkansas-cerebral-palsy}
\end{itemize}








% End the Document
%==============================================================================
\end{document}